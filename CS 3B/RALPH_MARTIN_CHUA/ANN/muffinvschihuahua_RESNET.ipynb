{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ef318d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lib imports (enhanced - include mixed precision optional)\n",
    "# ensure imports include applications\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers, callbacks, optimizers, applications\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f7b1996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET DIRECTORY CONFIGURATION (updated to use your dataset)\n",
    "train_dir = r\"C:\\Users\\Ralph\\Documents\\GitHub\\25-26\\CS 3B\\RALPH_MARTIN_CHUA\\ANN\\train\"\n",
    "test_dir  = r\"C:\\Users\\Ralph\\Documents\\GitHub\\25-26\\CS 3B\\RALPH_MARTIN_CHUA\\ANN\\test\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dd60d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE PARAMETERS (use ResNet input size)\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035de567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3788 images belonging to 2 classes.\n",
      "Found 945 images belonging to 2 classes.\n",
      "Found 1184 images belonging to 2 classes.\n",
      "Class indices: {'chihuahua': 0, 'muffin': 1}\n",
      "Train samples: 3788, Val samples: 945, Test samples: 1184\n"
     ]
    }
   ],
   "source": [
    "# DATA PREPROCESSING (ResNet)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=applications.resnet.preprocess_input,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=applications.resnet.preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"Class indices:\", train_generator.class_indices)\n",
    "print(f\"Train samples: {train_generator.samples}, Val samples: {val_generator.samples}, Test samples: {test_generator.samples}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da849e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               524544    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,090,625\n",
      "Trainable params: 525,313\n",
      "Non-trainable params: 23,565,312\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Build ResNet50V2 transfer-learning model\n",
    "weight_decay = 1e-4\n",
    "base_model = applications.ResNet50V2(include_top=False, weights='imagenet', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), pooling='avg')\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = layers.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = layers.Dense(256, kernel_regularizer=regularizers.l2(weight_decay), activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = models.Model(inputs, outputs)\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61daac50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      " 51/119 [===========>..................] - ETA: 1:10 - loss: 0.7740 - accuracy: 0.6225"
     ]
    }
   ],
   "source": [
    "# TRAIN / SAVE (use your lastname in the filename)\n",
    "MODEL_FILENAME = 'exercise_6_custom_resnet.h5'  # replace custom_lastname with your last name if desired\n",
    "\n",
    "checkpoint_path = MODEL_FILENAME\n",
    "callbacks_list = [\n",
    "    callbacks.ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "    callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=12,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ensure final save (ModelCheckpoint already saved best model)\n",
    "model.save(MODEL_FILENAME)\n",
    "print(f\"Saved improved model to {MODEL_FILENAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e78f88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 25s 682ms/step - loss: 0.4925 - accuracy: 0.8623\n",
      "Test Accuracy: 0.8623\n"
     ]
    }
   ],
   "source": [
    "# Load best-saved model and evaluate (uses preprocess_input via generators)\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(MODEL_FILENAME)\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463ea612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000016A5C39F760> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "test/chihuahua/img_0_5.jpg -> Prediction: chihuahua (confidence: 0.0184)\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000016A02050A60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 124ms/step\n",
      "test/muffin/img_0_32.jpg -> Prediction: muffin (confidence: 0.9918)\n",
      "Predictions saved to training_results.txt\n"
     ]
    }
   ],
   "source": [
    "# PREDICTION + WRITE RESULTS (use ResNet preprocessing)\n",
    "from ast import If\n",
    "\n",
    "\n",
    "MODEL_FILENAME = MODEL_FILENAME\n",
    "\n",
    "def predict_image_local(img_path, model_path=MODEL_FILENAME):\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "    import numpy as np\n",
    "    img = image.load_img(img_path, target_size=IMG_SIZE)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(applications.resnet.preprocess_input(img_array), axis=0)\n",
    "    pred = float(model.predict(img_array)[0,0])\n",
    "    label = \"muffin\" if pred >= 0.5 else \"chihuahua\"\n",
    "    print(f\"{img_path} -> Prediction: {label} (confidence: {pred:.4f})\")\n",
    "    return label, pred\n",
    "\n",
    "# Example prediction placeholders - update with actual images if desired\n",
    "label1, conf1 = predict_image_local(r\"test/chihuahua/img_0_5.jpg\")\n",
    "label2, conf2 = predict_image_local(r\"test/muffin/img_0_32.jpg\")\n",
    "\n",
    "#If predictions executed, write results:\n",
    "with open('training_results.txt', 'w') as f:\n",
    "  f.write(f\"Test Accuracy: {test_acc:.4f}\\n\")\n",
    "  f.write(f\"Run 1 - {label1} (confidence: {conf1:.4f})\\n\")\n",
    "  f.write(f\"Run 2 - {label2} (confidence: {conf2:.4f})\\n\")\n",
    "  print(\"Predictions saved to training_results.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env 3.10)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
