{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6904d94a",
   "metadata": {},
   "source": [
    "This is an example of a simple CNN developed, trained and utilized\n",
    "\n",
    "AI was used to help generate the codebase\n",
    "\n",
    "Note: Make sure that the tensorflow package is installed in your device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "52f3b56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ralph\\Desktop\\ANN\\tf-env\\Scripts\\python.exe\n",
      "3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "35c8ad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lib imports\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers, callbacks, optimizers\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6cf51c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET DIRECTORY CONFIGURATION (updated to use your pizzavsicecreamdataset)\n",
    "train_dir = r\"C:\\Users\\Ralph\\Documents\\GitHub\\25-26\\CS 3B\\RALPH_MARTIN_CHUA\\ANN\\pizzavsicecreamdataset\\train\"\n",
    "test_dir  = r\"C:\\Users\\Ralph\\Documents\\GitHub\\25-26\\CS 3B\\RALPH_MARTIN_CHUA\\ANN\\pizzavsicecreamdataset\\test\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ef4f9d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE PARAMETERS\n",
    "# Used to resize the input images, also will determine the input size of your input layer.\n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d350739e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 575 images belonging to 2 classes.\n",
      "Found 143 images belonging to 2 classes.\n",
      "Found 107 images belonging to 2 classes.\n",
      "Class indices: {'icecream': 0, 'pizza': 1}\n",
      "Train samples: 575, Val samples: 143, Test samples: 107\n"
     ]
    }
   ],
   "source": [
    "# DATA PREPROCESSING & AUGMENTATION (ensure labels match pizza/icecream)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"Class indices:\", train_generator.class_indices)\n",
    "print(f\"Train samples: {train_generator.samples}, Val samples: {val_generator.samples}, Test samples: {test_generator.samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3f4b1252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_21 (Conv2D)          (None, 128, 128, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 128, 128, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_24 (Activation)  (None, 128, 128, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 64, 64, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 64, 64, 32)        0         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 64, 64, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 64, 64, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_25 (Activation)  (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 32, 32, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 32, 32, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_26 (Activation)  (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 16, 16, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 256)               8388864   \n",
      "                                                                 \n",
      " batch_normalization_27 (Bat  (None, 256)              1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_27 (Activation)  (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,484,289\n",
      "Trainable params: 8,483,329\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# IMPROVED CNN MODEL ARCHITECTURE WITH REGULARIZATION, BATCHNORM, AND DROPOUT\n",
    "\n",
    "# hyperparams\n",
    "initial_learning_rate = 0.001\n",
    "weight_decay = 1e-4\n",
    "\n",
    "# LR schedule + optimizer\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True,\n",
    ")\n",
    "optimizer = optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "# Improved model: L2, BatchNorm, Dropout\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), padding='same',\n",
    "                  kernel_regularizer=regularizers.l2(weight_decay),\n",
    "                  input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), activation=None),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), padding='same',\n",
    "                  kernel_regularizer=regularizers.l2(weight_decay), activation=None),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Dropout(0.25),\n",
    "\n",
    "    layers.Conv2D(128, (3,3), padding='same',\n",
    "                  kernel_regularizer=regularizers.l2(weight_decay), activation=None),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Dropout(0.30),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, kernel_regularizer=regularizers.l2(weight_decay), activation=None),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "750c313f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.7285 - accuracy: 0.7930\n",
      "Epoch 1: val_accuracy improved from -inf to 0.54545, saving model to exercise_6_custom_lastname.h5\n",
      "18/18 [==============================] - 35s 2s/step - loss: 0.7285 - accuracy: 0.7930 - val_loss: 1.8111 - val_accuracy: 0.5455\n",
      "Epoch 2/12\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4704 - accuracy: 0.8435\n",
      "Epoch 2: val_accuracy did not improve from 0.54545\n",
      "18/18 [==============================] - 20s 1s/step - loss: 0.4704 - accuracy: 0.8435 - val_loss: 1.2165 - val_accuracy: 0.5455\n",
      "Epoch 3/12\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3853 - accuracy: 0.8887\n",
      "Epoch 3: val_accuracy did not improve from 0.54545\n",
      "18/18 [==============================] - 21s 1s/step - loss: 0.3853 - accuracy: 0.8887 - val_loss: 1.3957 - val_accuracy: 0.5455\n",
      "Epoch 4/12\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3390 - accuracy: 0.8870\n",
      "Epoch 4: val_accuracy did not improve from 0.54545\n",
      "18/18 [==============================] - 22s 1s/step - loss: 0.3390 - accuracy: 0.8870 - val_loss: 1.4849 - val_accuracy: 0.5455\n",
      "Epoch 5/12\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3038 - accuracy: 0.9130\n",
      "Epoch 5: val_accuracy did not improve from 0.54545\n",
      "18/18 [==============================] - 27s 2s/step - loss: 0.3038 - accuracy: 0.9130 - val_loss: 1.6219 - val_accuracy: 0.5455\n",
      "Epoch 6/12\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3660 - accuracy: 0.8939\n",
      "Epoch 6: val_accuracy did not improve from 0.54545\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "18/18 [==============================] - 24s 1s/step - loss: 0.3660 - accuracy: 0.8939 - val_loss: 1.6839 - val_accuracy: 0.5455\n",
      "Epoch 6: early stopping\n",
      "Saved improved model to exercise_6_custom_lastname.h5\n"
     ]
    }
   ],
   "source": [
    "# TRAIN / SAVE (use your lastname in the filename)\n",
    "MODEL_FILENAME = 'exercise_6_custom_lastname.h5'  # replace custom_lastname with your last name if desired\n",
    "\n",
    "checkpoint_path = MODEL_FILENAME\n",
    "callbacks_list = [\n",
    "    callbacks.ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "    callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=12,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks_list,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ensure final save (ModelCheckpoint already saved best model)\n",
    "model.save(MODEL_FILENAME)\n",
    "print(f\"Saved improved model to {MODEL_FILENAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7541833a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 5s 1s/step - loss: 1.7564 - accuracy: 0.5514\n",
      "Test Accuracy: 0.5514\n"
     ]
    }
   ],
   "source": [
    "# Load best-saved model and evaluate\n",
    "from tensorflow.keras.models import load_model\n",
    "MODEL_FILENAME = 'exercise_6_custom_lastname.h5'  # same name used above\n",
    "\n",
    "model = load_model(MODEL_FILENAME)\n",
    "test_loss, test_acc = model.evaluate(test_generator, verbose=1)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2ad7d399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE THE MODEL\n",
    "model.save('muffin_vs_chihuahua_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "45472d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 562ms/step\n",
      "pizzavsicecreamdataset/test/icecream/0072_jpg.rf.aec373e259dc03153312c64dd0bb9b4d.jpg -> Prediction: icecream (confidence: 0.0096)\n",
      "1/1 [==============================] - 0s 375ms/step\n",
      "pizzavsicecreamdataset/test/pizza/00100_jpg.rf.743db856627866dbc7c6d3af90afd0e2.jpg -> Prediction: icecream (confidence: 0.0210)\n",
      "Predictions saved to training_results.txt\n"
     ]
    }
   ],
   "source": [
    "# PREDICTION + WRITE RESULTS (updated labels and fixed filename typo)\n",
    "MODEL_FILENAME = 'exercise_6_custom_lastname.h5'  # change custom_lastname -> your lastname if desired\n",
    "\n",
    "def predict_image_local(img_path, model_path=MODEL_FILENAME):\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    from tensorflow.keras.preprocessing import image\n",
    "    import numpy as np\n",
    "    img = image.load_img(img_path, target_size=IMG_SIZE)\n",
    "    img_array = image.img_to_array(img) / 255.0\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    pred = float(model.predict(img_array)[0,0])\n",
    "    label = \"pizza\" if pred >= 0.5 else \"icecream\"   # matches your dataset\n",
    "    print(f\"{img_path} -> Prediction: {label} (confidence: {pred:.4f})\")\n",
    "    return label, pred\n",
    "\n",
    "# example test images from your dataset (adjust filenames if different)\n",
    "label1, conf1 = predict_image_local(r\"pizzavsicecreamdataset/test/icecream/0072_jpg.rf.aec373e259dc03153312c64dd0bb9b4d.jpg\")\n",
    "label2, conf2 = predict_image_local(r\"pizzavsicecreamdataset/test/pizza/00100_jpg.rf.743db856627866dbc7c6d3af90afd0e2.jpg\")  # replace with an actual muffin test image\n",
    "\n",
    "# write results (requires test_acc from evaluation cell)\n",
    "with open('training_results.txt', 'w') as f:\n",
    "    f.write(f\"Test Accuracy: {test_acc:.4f}\\n\")\n",
    "    f.write(f\"Run 1 - {label1} (confidence: {conf1:.4f})\\n\")\n",
    "    f.write(f\"Run 2 - {label2} (confidence: {conf2:.4f})\\n\")\n",
    "\n",
    "print(\"Predictions saved to training_results.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env 3.10)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
