{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6904d94a",
   "metadata": {},
   "source": [
    "This is an example of a simple CNN developed, trained and utilized\n",
    "\n",
    "AI was used to help generate the codebase\n",
    "\n",
    "Note: Make sure that the tensorflow package is installed in your device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c8ad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lib imports\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6cf51c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET DIRECTORY CONFIGURATION\n",
    "# Download and unzip the dataset from Kaggle, set the directory paths accordingly.\n",
    "train_dir = \"./train1\"  # e.g. './muffin-vs-chihuahua/train'\n",
    "test_dir = \"./test1\"    # e.g. './muffin-vs-chihuahua/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ef4f9d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMAGE PARAMETERS\n",
    "# Used to resize the input images, also will determine the input size of your input layer.\n",
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d350739e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1280 images belonging to 2 classes.\n",
      "Found 320 images belonging to 2 classes.\n",
      "Found 15 images belonging to 2 classes.\n",
      "Found 320 images belonging to 2 classes.\n",
      "Found 15 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# DATA PREPROCESSING & AUGMENTATION (ResNet50 preprocessing)\n",
    "# Using preprocess_input for ResNet50 (ImageNet mean subtraction & channel handling)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4b1252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESNET50 TRANSFER LEARNING MODEL ARCHITECTURE\n",
    "# Load pretrained ResNet50 without top classifier\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "# Freeze base layers for initial training phase\n",
    "base_model.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = models.Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Optional fine-tuning strategy (uncomment later):\n",
    "# for layer in base_model.layers[-20:]:\n",
    "#     layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dcbcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile with low LR suitable for frozen base transfer learning\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750c313f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 455ms/step - accuracy: 0.6195 - loss: 0.9513 - val_accuracy: 0.7000 - val_loss: 0.8061\n",
      "Epoch 2/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 455ms/step - accuracy: 0.6195 - loss: 0.9513 - val_accuracy: 0.7000 - val_loss: 0.8061\n",
      "Epoch 2/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 403ms/step - accuracy: 0.7227 - loss: 0.7509 - val_accuracy: 0.7281 - val_loss: 0.6804\n",
      "Epoch 3/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 403ms/step - accuracy: 0.7227 - loss: 0.7509 - val_accuracy: 0.7281 - val_loss: 0.6804\n",
      "Epoch 3/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 354ms/step - accuracy: 0.7531 - loss: 0.6509 - val_accuracy: 0.7812 - val_loss: 0.5981\n",
      "Epoch 4/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 354ms/step - accuracy: 0.7531 - loss: 0.6509 - val_accuracy: 0.7812 - val_loss: 0.5981\n",
      "Epoch 4/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 352ms/step - accuracy: 0.7930 - loss: 0.5684 - val_accuracy: 0.7812 - val_loss: 0.5793\n",
      "Epoch 5/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 352ms/step - accuracy: 0.7930 - loss: 0.5684 - val_accuracy: 0.7812 - val_loss: 0.5793\n",
      "Epoch 5/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 356ms/step - accuracy: 0.7797 - loss: 0.5580 - val_accuracy: 0.7781 - val_loss: 0.5635\n",
      "Epoch 6/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 356ms/step - accuracy: 0.7797 - loss: 0.5580 - val_accuracy: 0.7781 - val_loss: 0.5635\n",
      "Epoch 6/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 363ms/step - accuracy: 0.7766 - loss: 0.5533 - val_accuracy: 0.7906 - val_loss: 0.5318\n",
      "Epoch 7/10\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 363ms/step - accuracy: 0.7766 - loss: 0.5533 - val_accuracy: 0.7906 - val_loss: 0.5318\n",
      "Epoch 7/10\n",
      "\u001b[1m 1/40\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 410ms/step - accuracy: 0.9062 - loss: 0.3691"
     ]
    }
   ],
   "source": [
    "# TRAINING THE CNN\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7541833a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.8000 - loss: 0.4295\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.8000 - loss: 0.4295\n",
      "Test Accuracy: 0.800000011920929\n",
      "Test Accuracy: 0.800000011920929\n"
     ]
    }
   ],
   "source": [
    "# EVALUATE THE MODEL\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad7d399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# SAVE THE MODEL\n",
    "model.save('exercise_6_custom_capayan.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45472d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMPLE INFERENCE SCRIPT (ResNet50-based model)\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Cache the loaded model to avoid re-loading on every prediction\n",
    "_model_cache = {}\n",
    "\n",
    "def predict_image(img_path, model_path='exercise_6_trained_model_improved.h5'):\n",
    "    \"\"\"Predict whether the image is Cat or Rabbit using the ResNet50 transfer model.\n",
    "    Args:\n",
    "        img_path (str): Path to the input image.\n",
    "        model_path (str): Path to the saved Keras model (.h5).\n",
    "    \"\"\"\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file not found: {model_path}. Run training & save cells first.\")\n",
    "    if not os.path.exists(img_path):\n",
    "        raise FileNotFoundError(f\"Image file not found: {img_path}. Check path and working directory.\")\n",
    "\n",
    "    # Load model once and reuse\n",
    "    if model_path not in _model_cache:\n",
    "        _model_cache[model_path] = tf.keras.models.load_model(model_path, compile=False)\n",
    "    model = _model_cache[model_path]\n",
    "\n",
    "    img = image.load_img(img_path, target_size=IMG_SIZE)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = preprocess_input(img_array)  # ResNet50 preprocessing\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    pred = float(model.predict(img_array)[0, 0])\n",
    "    label = \"Cat\" if pred >= 0.5 else \"Rabbit\"\n",
    "    confidence = pred if pred >= 0.5 else 1.0 - pred\n",
    "    print(f\"Prediction: {label} (confidence: {confidence:.2f}) from raw score {pred:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b340f1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Prediction: Rabbit (confidence: 0.97) from raw score 0.03\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Prediction: Rabbit (confidence: 0.97) from raw score 0.03\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Prediction: Cat (confidence: 0.95) from raw score 0.95\n",
      "Prediction: Cat (confidence: 0.95) from raw score 0.95\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "predict_image(\"test1/cat/cat.208.jpg\")\n",
    "predict_image(\"test1/rabbit/images-2.jpeg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
