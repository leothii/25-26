{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6904d94a",
      "metadata": {
        "id": "6904d94a"
      },
      "source": [
        "This is an example of a simple CNN developed, trained and utilized\n",
        "\n",
        "AI was used to help generate the codebase\n",
        "\n",
        "Note: Make sure that the tensorflow package is installed in your device."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We installed the necessary packages for this project\n",
        "!pip install tensorflow opencv-python matplotlib numpy pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDJuI9S0BEzi",
        "outputId": "2f1321cf-5c78-467c-b322-803989e59c3c"
      },
      "id": "DDJuI9S0BEzi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P28UW7hlBI9J",
        "outputId": "9715d33a-d2a4-4abf-c4fe-4c81d817e93a"
      },
      "id": "P28UW7hlBI9J",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from keras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras) (3.15.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras) (0.5.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from optree->keras) (4.15.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I installed kagglehub to download and manage Kaggle datasets easily\n",
        "!pip install kagglehub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eY9wrVNDBLdm",
        "outputId": "d3488699-74da-42b7-be7f-97d9689d34dc"
      },
      "id": "eY9wrVNDBLdm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# We downloaded the Muffin vs Chihuahua dataset from Kaggle\n",
        "path = kagglehub.dataset_download(\"samuelcortinhas/muffin-vs-chihuahua-image-classification\")\n",
        "\n",
        "print(\"Dataset downloaded to:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OU4ZEN85BNgb",
        "outputId": "dbe14ece-967e-4483-de3e-75a2b6b59dee"
      },
      "id": "OU4ZEN85BNgb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'muffin-vs-chihuahua-image-classification' dataset.\n",
            "Dataset downloaded to: /kaggle/input/muffin-vs-chihuahua-image-classification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.listdir(\"/kaggle/input/muffin-vs-chihuahua-image-classification\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGQBsUB5BQuP",
        "outputId": "c347450b-72f0-4f44-e7db-8c7b43dad6a4"
      },
      "id": "lGQBsUB5BQuP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['test', 'train']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = os.path.join(path, \"train\")\n",
        "test_dir  = os.path.join(path, \"test\")\n",
        "\n",
        "print(\"Train folder:\", train_dir)\n",
        "print(\"Test folder:\", test_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFBr_XadwLmg",
        "outputId": "368c0d77-e2a5-4c14-ffe6-9ecc801c5212"
      },
      "id": "pFBr_XadwLmg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train folder: /kaggle/input/muffin-vs-chihuahua-image-classification/train\n",
            "Test folder: /kaggle/input/muffin-vs-chihuahua-image-classification/test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35c8ad95",
      "metadata": {
        "id": "35c8ad95"
      },
      "outputs": [],
      "source": [
        "# Lib imports\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models, regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cf51c0b",
      "metadata": {
        "id": "6cf51c0b"
      },
      "outputs": [],
      "source": [
        "# DATASET DIRECTORY CONFIGURATION\n",
        "# Download and unzip the dataset from Kaggle, set the directory paths accordingly.\n",
        "train_dir = path + \"/train\"\n",
        "test_dir  = path + \"/test\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef4f9d80",
      "metadata": {
        "id": "ef4f9d80"
      },
      "outputs": [],
      "source": [
        "# IMAGE PARAMETERS\n",
        "# Used to resize the input images, also will determine the input size of your input layer.\n",
        "IMG_SIZE = (128, 128)\n",
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d350739e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d350739e",
        "outputId": "c1eb6615-02c2-43d5-a74c-b3cc054b67eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3788 images belonging to 2 classes.\n",
            "Found 945 images belonging to 2 classes.\n",
            "Found 1184 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# DATA PREPROCESSING & AUGMENTATION\n",
        "# Optional but recommended for image processing tasks, especially with limited data.\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2\n",
        ")\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='training',\n",
        ")\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation'\n",
        ")\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f4b1252",
      "metadata": {
        "id": "3f4b1252"
      },
      "outputs": [],
      "source": [
        "# SIMPLE CNN MODEL ARCHITECTURE\n",
        "\n",
        "# Some modifications are applied\n",
        "initial_learning_rate = 0.001\n",
        "# We are combining ExponentialDecay with Adam optimizer for better learning rate management\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9,\n",
        "    staircase=True\n",
        ")\n",
        "\n",
        "# Create the optimizer with the learning rate schedule\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "# Applied dropout layers to reduce overfitting and L2 regularization\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                  kernel_regularizer=tf.keras.regularizers.l2(0.001),\n",
        "                  input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu',\n",
        "                  kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Conv2D(128, (3, 3), activation='relu',\n",
        "                  kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    layers.MaxPooling2D(2, 2),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu',\n",
        "                 kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71dcbcb7",
      "metadata": {
        "id": "71dcbcb7"
      },
      "outputs": [],
      "source": [
        "# Configure the model optimizers, loss function, and metrics\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) # old\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "750c313f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "750c313f",
        "outputId": "90c21345-4da8-4a9f-a90e-ed0747fa5ead"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 1s/step - accuracy: 0.5726 - loss: 1.0772 - val_accuracy: 0.6899 - val_loss: 0.7575\n",
            "Epoch 2/15\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 1s/step - accuracy: 0.7205 - loss: 0.7012 - val_accuracy: 0.7831 - val_loss: 0.5858\n",
            "Epoch 3/15\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 1s/step - accuracy: 0.7847 - loss: 0.5742 - val_accuracy: 0.7979 - val_loss: 0.5628\n",
            "Epoch 4/15\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 1s/step - accuracy: 0.8045 - loss: 0.5141 - val_accuracy: 0.8434 - val_loss: 0.4464\n",
            "Epoch 5/15\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 1s/step - accuracy: 0.8045 - loss: 0.4872 - val_accuracy: 0.8212 - val_loss: 0.4469\n",
            "Epoch 6/15\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 1s/step - accuracy: 0.8286 - loss: 0.4678 - val_accuracy: 0.8794 - val_loss: 0.3803\n",
            "Epoch 7/15\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 1s/step - accuracy: 0.8402 - loss: 0.4395 - val_accuracy: 0.7884 - val_loss: 0.4989\n",
            "Epoch 8/15\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 1s/step - accuracy: 0.8304 - loss: 0.4461 - val_accuracy: 0.8889 - val_loss: 0.3450\n",
            "Epoch 9/15\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 1s/step - accuracy: 0.8395 - loss: 0.4305 - val_accuracy: 0.8593 - val_loss: 0.3982\n",
            "Epoch 10/15\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 1s/step - accuracy: 0.8495 - loss: 0.4313 - val_accuracy: 0.9016 - val_loss: 0.3000\n",
            "Epoch 11/15\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 1s/step - accuracy: 0.8596 - loss: 0.3995 - val_accuracy: 0.9069 - val_loss: 0.3170\n",
            "Epoch 12/15\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 1s/step - accuracy: 0.8538 - loss: 0.3850 - val_accuracy: 0.8868 - val_loss: 0.3241\n",
            "Epoch 13/15\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 1s/step - accuracy: 0.8634 - loss: 0.3801 - val_accuracy: 0.8762 - val_loss: 0.3550\n",
            "Epoch 14/15\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 1s/step - accuracy: 0.8718 - loss: 0.3559 - val_accuracy: 0.9111 - val_loss: 0.2939\n",
            "Epoch 15/15\n",
            "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 1s/step - accuracy: 0.8850 - loss: 0.3453 - val_accuracy: 0.8635 - val_loss: 0.3590\n"
          ]
        }
      ],
      "source": [
        "# TRAINING THE CNN\n",
        "\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',  # watch the validation loss\n",
        "    patience=3,          # stop if no improvement for 3 epochs\n",
        "    restore_best_weights=True  # restore weights from the best epoch\n",
        ")\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=15,\n",
        "    validation_data=val_generator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7541833a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7541833a",
        "outputId": "76837017-ab29-42e7-9708-bf264cfc2889"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 406ms/step - accuracy: 0.9329 - loss: 0.2393\n",
            "Test Accuracy: 0.8589527010917664\n"
          ]
        }
      ],
      "source": [
        "# a. (5 points) Accuracy\n",
        "# EVALUATE THE MODEL\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print(f\"Test Accuracy: {test_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ad7d399",
      "metadata": {
        "id": "2ad7d399"
      },
      "outputs": [],
      "source": [
        "# c. (10 points) Rename the trained CNN model to “exercise_6_trained_model_improved.h5”\n",
        "# SAVE THE MODEL\n",
        "model.save(\"exercise_6_trained_model_improved.h5\")\n",
        "print(\"Model saved as 'exercise_6_trained_model_improved.h5'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45472d3e",
      "metadata": {
        "id": "45472d3e"
      },
      "outputs": [],
      "source": [
        "# b. (10 points) Run 1 and 2’s prediction and confidence\n",
        "# SIMPLE INFERENCE SCRIPT\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "def predict_image(img_path, model_path='exercise_6_trained_model_improved.h5'):\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "    img = image.load_img(img_path, target_size=(128, 128))\n",
        "    img_array = image.img_to_array(img) / 255.0\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # pred is P(Muffin) based on flow_from_directory's alphabetical order\n",
        "    prob_muffin = model.predict(img_array)[0,0]\n",
        "\n",
        "    # Determine the predicted class and its confidence\n",
        "    if prob_muffin >= 0.5:\n",
        "        label = \"Muffin\"\n",
        "        confidence = prob_muffin\n",
        "    else:\n",
        "        label = \"Chihuahua\"\n",
        "        # P(Chihuahua) = 1 - P(Muffin)\n",
        "        confidence = 1.0 - prob_muffin\n",
        "\n",
        "    print(f\"Prediction: {label} (confidence: {confidence:.2f})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b340f1d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b340f1d2",
        "outputId": "832cbc2d-7ab5-403b-fd42-e149ad4b2943"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step\n",
            "Prediction: Muffin (confidence: 0.53)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
            "Prediction: Muffin (confidence: 1.00)\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "predict_image(\"run_1.jpg\")\n",
        "predict_image(\"run_2.jpg\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}