{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90546065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Task 1 & 2 Data from: ./muffin_chihuahua\n",
      "Found 4733 images belonging to 2 classes.\n",
      "Found 1184 images belonging to 2 classes.\n",
      "Loading Task 3 & 4 Data from: ./pizza_notpizza\n",
      "Found 1966 images belonging to 2 classes.\n",
      "Found 1966 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "MY_LAST_NAME = \"Bocala\" \n",
    "\n",
    "# --- FOLDER NAMES (UPDATED) ---\n",
    "MC_FOLDER = './muffin_chihuahua'       # For Task 1 & 2\n",
    "CUSTOM_FOLDER = './pizza_notpizza'     # For Task 3 & 4\n",
    "\n",
    "IMG_SIZE = (150, 150)\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "# --- DATA GENERATORS ---\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "print(f\"Loading Task 1 & 2 Data from: {MC_FOLDER}\")\n",
    "# Check if folder exists to prevent crash\n",
    "if not os.path.exists(MC_FOLDER):\n",
    "    print(f\"ERROR: Folder '{MC_FOLDER}' not found. Please check your directory.\")\n",
    "else:\n",
    "    train_mc = datagen.flow_from_directory(\n",
    "        os.path.join(MC_FOLDER, 'train'),\n",
    "        target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary')\n",
    "\n",
    "    test_mc = datagen.flow_from_directory(\n",
    "        os.path.join(MC_FOLDER, 'test'),\n",
    "        target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary')\n",
    "\n",
    "print(f\"Loading Task 3 & 4 Data from: {CUSTOM_FOLDER}\")\n",
    "if not os.path.exists(CUSTOM_FOLDER):\n",
    "    print(f\"ERROR: Folder '{CUSTOM_FOLDER}' not found. Please check your directory.\")\n",
    "else:\n",
    "    train_custom = datagen.flow_from_directory(\n",
    "        os.path.join(CUSTOM_FOLDER, 'train'),\n",
    "        target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary')\n",
    "\n",
    "    test_custom = datagen.flow_from_directory(\n",
    "        os.path.join(CUSTOM_FOLDER, 'test'),\n",
    "        target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f0edb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STARTING TASK 2: IMPROVED CNN ---\n",
      "Epoch 1/5\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 1s/step - accuracy: 0.7148 - loss: 0.8068 - val_accuracy: 0.8480 - val_loss: 0.4837\n",
      "Epoch 2/5\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 1s/step - accuracy: 0.8358 - loss: 0.4532 - val_accuracy: 0.8843 - val_loss: 0.3767\n",
      "Epoch 3/5\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 856ms/step - accuracy: 0.8519 - loss: 0.4124 - val_accuracy: 0.8801 - val_loss: 0.3738\n",
      "Epoch 4/5\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 835ms/step - accuracy: 0.8633 - loss: 0.3772 - val_accuracy: 0.8750 - val_loss: 0.3829\n",
      "Epoch 5/5\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 819ms/step - accuracy: 0.8749 - loss: 0.3653 - val_accuracy: 0.8885 - val_loss: 0.3482\n",
      "\n",
      "[ANSWER Q2a] Final Accuracy: 88.85%\n",
      "\n",
      "[ANSWER Q2b] Prediction Check:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: ./muffin_chihuahua/test\\chihuahua\\img_0_1071.jpg\n",
      "Prediction: Class 0 | Confidence: 92.66%\n",
      ">>> SAVED: exercise_6_trained_model_improved.h5\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- STARTING TASK 2: IMPROVED CNN ---\")\n",
    "\n",
    "# 1. Define Model with Improvements\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    \n",
    "    # --- REQUIRED IMPROVEMENTS ---\n",
    "    layers.Dropout(0.5), \n",
    "    layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 2. Train on Muffin/Chihuahua\n",
    "history = model.fit(train_mc, epochs=5, validation_data=test_mc)\n",
    "\n",
    "# 3. Answer Question 2a (Accuracy)\n",
    "acc = history.history['val_accuracy'][-1]\n",
    "print(f\"\\n[ANSWER Q2a] Final Accuracy: {acc*100:.2f}%\")\n",
    "\n",
    "# 4. Answer Question 2b (Prediction & Confidence)\n",
    "print(\"\\n[ANSWER Q2b] Prediction Check:\")\n",
    "try:\n",
    "    # Pick first image in test folder\n",
    "    sample_path = glob.glob(f'{MC_FOLDER}/test/*/*.jpg')[0]\n",
    "    \n",
    "    img = load_img(sample_path, target_size=IMG_SIZE)\n",
    "    x = img_to_array(img) / 255.0\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    \n",
    "    pred = model.predict(x)[0][0]\n",
    "    lbl = \"Class 1\" if pred > 0.5 else \"Class 0\"\n",
    "    conf = pred if pred > 0.5 else 1-pred\n",
    "    \n",
    "    print(f\"Image: {sample_path}\")\n",
    "    print(f\"Prediction: {lbl} | Confidence: {conf:.2%}\")\n",
    "except:\n",
    "    print(\"Could not find a test image to predict.\")\n",
    "\n",
    "# 5. Answer Question 2c (Save Model)\n",
    "model.save('exercise_6_trained_model_improved.h5')\n",
    "print(\">>> SAVED: exercise_6_trained_model_improved.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "978bfef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: ./pizza_notpizza\n",
      "Found 1966 images belonging to 2 classes.\n",
      "Found 1966 images belonging to 2 classes.\n",
      "Starting Training...\n",
      "Epoch 1/5\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 960ms/step - accuracy: 0.6104 - loss: 1.1129 - val_accuracy: 0.6628 - val_loss: 0.7834\n",
      "Epoch 2/5\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 914ms/step - accuracy: 0.7045 - loss: 0.6806 - val_accuracy: 0.7731 - val_loss: 0.5890\n",
      "Epoch 3/5\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 909ms/step - accuracy: 0.7228 - loss: 0.6057 - val_accuracy: 0.7798 - val_loss: 0.5192\n",
      "Epoch 4/5\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 906ms/step - accuracy: 0.7675 - loss: 0.5354 - val_accuracy: 0.7976 - val_loss: 0.5098\n",
      "Epoch 5/5\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 916ms/step - accuracy: 0.7813 - loss: 0.5287 - val_accuracy: 0.8225 - val_loss: 0.4619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> SAVED SUCCESSFULLY: exercise_6_custom_Bocala.h5\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# TASK 3: CUSTOM DATASET (Clean Version)\n",
    "# ==========================================\n",
    "import os\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 1. CONFIGURATION\n",
    "MY_LAST_NAME = \"Bocala\" \n",
    "# Use the fixed path. \n",
    "# If you moved the folders, change this to './pizza_notpizza'\n",
    "# If it's still nested, keep './pizza_notpizza/pizza_notpizza'\n",
    "CUSTOM_FOLDER = './pizza_notpizza' \n",
    "\n",
    "IMG_SIZE = (150, 150)\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "# 2. LOAD DATA (Creates 'train_custom' so the code works)\n",
    "print(f\"Loading data from: {CUSTOM_FOLDER}\")\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "if os.path.exists(CUSTOM_FOLDER):\n",
    "    train_custom = datagen.flow_from_directory(\n",
    "        os.path.join(CUSTOM_FOLDER, 'train'),\n",
    "        target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary')\n",
    "\n",
    "    test_custom = datagen.flow_from_directory(\n",
    "        os.path.join(CUSTOM_FOLDER, 'test'),\n",
    "        target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='binary')\n",
    "else:\n",
    "    print(\"❌ ERROR: Folder not found. Check the path.\")\n",
    "\n",
    "# 3. TRAIN MODEL (Original Task 3 Logic)\n",
    "print(\"Starting Training...\")\n",
    "\n",
    "# Clone the Task 2 model structure\n",
    "model_custom = models.clone_model(model)\n",
    "model_custom.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "model_custom.fit(train_custom, epochs=5, validation_data=test_custom)\n",
    "\n",
    "# 4. SAVE\n",
    "filename = f'exercise_6_custom_{MY_LAST_NAME}.h5'\n",
    "model_custom.save(filename)\n",
    "print(f\">>> SAVED SUCCESSFULLY: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfe877ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- STARTING TASK 4: TRANSFER LEARNING (VGG16) ---\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1us/step\n",
      "Epoch 1/5\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 3s/step - accuracy: 0.8057 - loss: 0.4652 - val_accuracy: 0.9064 - val_loss: 0.2674\n",
      "Epoch 2/5\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m252s\u001b[0m 3s/step - accuracy: 0.8830 - loss: 0.2902 - val_accuracy: 0.9430 - val_loss: 0.1818\n",
      "Epoch 3/5\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 3s/step - accuracy: 0.9095 - loss: 0.2243 - val_accuracy: 0.9573 - val_loss: 0.1401\n",
      "Epoch 4/5\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 3s/step - accuracy: 0.9334 - loss: 0.1785 - val_accuracy: 0.9695 - val_loss: 0.1006\n",
      "Epoch 5/5\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 3s/step - accuracy: 0.9517 - loss: 0.1400 - val_accuracy: 0.9746 - val_loss: 0.0753\n",
      ">>> TASK 4 COMPLETE. ALL EXERCISES FINISHED.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- STARTING TASK 4: TRANSFER LEARNING (VGG16) ---\")\n",
    "\n",
    "# 1. Load VGG16\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "base_model.trainable = False \n",
    "\n",
    "# 2. Create Transfer Model\n",
    "transfer_model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "transfer_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 3. Train on PIZZA/NOTPIZZA\n",
    "transfer_model.fit(train_custom, epochs=5, validation_data=test_custom)\n",
    "\n",
    "print(\">>> TASK 4 COMPLETE. ALL EXERCISES FINISHED.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
