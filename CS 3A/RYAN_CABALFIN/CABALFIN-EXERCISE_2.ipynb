{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34e154ad",
   "metadata": {},
   "source": [
    "# Unit 2 – Iris Dataset\n",
    "Neural Network Forward Pass with Manual and Code-Based Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4ab23600",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde92294",
   "metadata": {},
   "source": [
    "## Input and Target Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "26a11e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([5.1, 3.5, 1.4, 0.2])\n",
    "target = np.array([0.7, 0.2, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099d4d03",
   "metadata": {},
   "source": [
    "## Dense Layer Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ea83bffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense_Layer:\n",
    "    def __init__(self, weights, bias, activation):\n",
    "        self.weights = np.array(weights, dtype=float)\n",
    "        self.bias = np.array(bias, dtype=float)\n",
    "        self.activation = activation\n",
    "\n",
    "    def weighted_sum(self, inputs):\n",
    "        return np.dot(inputs, self.weights) + self.bias\n",
    "\n",
    "    def activate(self, z):\n",
    "        if self.activation == \"relu\":\n",
    "            return np.maximum(0, z)\n",
    "        elif self.activation == \"sigmoid\":\n",
    "            return 1 / (1 + np.exp(-z))\n",
    "        elif self.activation == \"softmax\":\n",
    "            e = np.exp(z - np.max(z))\n",
    "            return e / np.sum(e)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation\")\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        z = self.weighted_sum(inputs)\n",
    "        return self.activate(z)\n",
    "\n",
    "    def categorical_cross_entropy_loss(self, predicted, target):\n",
    "        predicted = np.clip(predicted, 1e-15, 1 - 1e-15)\n",
    "        return -np.sum(target * np.log(predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432ae7ab",
   "metadata": {},
   "source": [
    "## Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d1c105bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = [\n",
    "    [0.2,  0.5, -0.3],\n",
    "    [0.1, -0.2,  0.4],\n",
    "    [-0.4, 0.3,  0.2],\n",
    "    [0.6, -0.1,  0.5]\n",
    "]\n",
    "B1 = [3.0, -2.1, 0.6]\n",
    "\n",
    "W2 = [\n",
    "    [0.3, -0.5],\n",
    "    [0.7,  0.2],\n",
    "    [-0.6, 0.4]\n",
    "]\n",
    "B2 = [4.3, 6.4]\n",
    "\n",
    "W3 = [\n",
    "    [0.5, -0.3, 0.8],\n",
    "    [-0.2, 0.6, -0.4]\n",
    "]\n",
    "B3 = [-1.5, 2.1, -3.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d01461",
   "metadata": {},
   "source": [
    "## Forward Pass – Hidden Layer 1 (ReLU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "966abe8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.93, 0.15, 0.85])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1 = Dense_Layer(W1, B1, \"relu\")\n",
    "A1 = layer1.forward(X)\n",
    "A1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653165d2",
   "metadata": {},
   "source": [
    "## Forward Pass – Hidden Layer 2 (Sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a9096ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99378157, 0.99187781])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2 = Dense_Layer(W2, B2, \"sigmoid\")\n",
    "A2 = layer2.forward(A1)\n",
    "A2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d685cbc3",
   "metadata": {},
   "source": [
    "## Output Layer (Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ae3b9a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0265075 , 0.96865119, 0.00484132])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer3 = Dense_Layer(W3, B3, \"softmax\")\n",
    "output = layer3.forward(A2)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7554a7d7",
   "metadata": {},
   "source": [
    "## Loss Calculation (Categorical Cross-Entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a4364796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.080656405230887)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = layer3.categorical_cross_entropy_loss(output, target)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535b7d8d",
   "metadata": {},
   "source": [
    "## Final Result\n",
    "\n",
    "- Predicted Class: **Iris-versicolor**\n",
    "- Loss Value Computed Successfully"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
